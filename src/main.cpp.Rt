<?R
        source("conf.R")
	c_header();
?>
/*  Main program file                                          */
/*     Here we have all the initialization and the main loop   */
/*-------------------------------------------------------------*/

#include "Consts.h"
#include "Global.h"
#include <mpi.h>
#include "Region.h"
#include "utils.h"
#include "unit.h"

#include <fstream>
#include <iostream>
#include <vector>
#include <iomanip>
#include <assert.h>

// for isatty
//#include <unistd.h>

#include "Solver.h"



// Reads units from configure file and applies them to the solver
void readUnits(pugi::xml_node config, Solver* solver) {
	pugi::xml_node set = config.child("Units");
	if (!set) {
		warning("No \"Units\" element in config file\n");
		return;
	}
	for (pugi::xml_node node = set.child("Params"); node; node = node.next_sibling("Params")) {
		std::string nm="", val="", gauge="1";
		for (pugi::xml_attribute attr = node.first_attribute(); attr; attr = attr.next_attribute())
		{
			if (((std::string) attr.name()) == "gauge") {
				gauge = attr.value();
			} else {
				if (nm != "") {
					error("Only one variable allowed in a Params element in Units (%s)\n", nm.c_str());
				}
				nm = attr.name();
				val= attr.value();
			}
		}
		if (nm == "") {
			error("No variable in a Params element in Units\n");
		}
		debug2("Units: %s = %s = %s\n", nm.c_str(), val.c_str(), gauge.c_str());
		solver->setUnit(nm, val, gauge);
	}
	solver->Gauge();
};

CudaEvent_t     start, stop; // CUDA events to measure time

// Main callback function called every some iterations to display speed
int MainCallback(int iter, Solver* solver) {
	static int cum_iter =0;
	static double cum_time = 0;
	int steps;
	float   elapsedTime; // Elapsed times
	CudaEventRecord( stop, 0 );
	CudaEventSynchronize( stop );
	CudaEventElapsedTime( &elapsedTime, start, stop );
	if (D_MPI_RANK == 0) {
		int desired_steps;
		if (iter >= 0) {
			cum_iter += iter;
			cum_time += elapsedTime;
	       		int ups = (float) (1000.*iter)/elapsedTime; // Steps made per second
       			double lbups=1.0;
       			lbups *= solver->info.region.nx;
			lbups *= solver->info.region.ny;
       			lbups *= solver->info.region.nz;
       			lbups *= iter;
			lbups /= elapsedTime;
			desired_steps = ups/desired_fps; // Desired steps per frame (so that on next frame fps = desired_fps)
			if (D_TERMINAL) {
				printf("[  ] %8.1f MLBUps   %7.2f GB/s                        \r", ((double)lbups)/1000, ( (double) lbups * ((double) 2 * NUMBER_OF_DENSITIES * sizeof(real_t) + sizeof(flag_t))) / 1e6);
			} else {
				printf("[  ] %8.1f MLBUps   %7.2f GB/s                        \n", ((double)lbups)/1000, ( (double) lbups * ((double) 2 * NUMBER_OF_DENSITIES * sizeof(real_t) + sizeof(flag_t))) / 1e6);
			}
			fflush(stdout);
		} else {
			cum_iter += - iter - 1;
			cum_time += elapsedTime;
	       		int ups = (float) (1000.*cum_iter)/cum_time; // Steps made per second
       			double lbups=1.0;
       			lbups *= solver->info.region.nx;
			lbups *= solver->info.region.ny;
       			lbups *= solver->info.region.nz;
       			lbups *= cum_iter;
			lbups /= cum_time;
			desired_steps = ups/desired_fps; // Desired steps per frame (so that on next frame fps = desired_fps)
			output("%8.1f MLBUps   %7.2f GB/s (avg)                  \n",
				((double)lbups)/1000,
				( (double) lbups * ((double) 2 * NUMBER_OF_DENSITIES * sizeof(real_t) + sizeof(flag_t))) / 1e6);
			fflush(stdout);
			cum_iter = 0;
			cum_time = 0;
		}
		steps = desired_steps;
		if (steps < 1) steps = 1;
		if (steps % 2 == 1) steps ++;
	}
	MPI_Bcast(&steps, 1, MPI_INT, 0, MPI_COMM_WORLD);
	solver->EventLoop();
	CudaEventRecord( start, 0 );
	CudaEventSynchronize( start );
	return steps;
}

// Finds the adjoint element in config to know how many snaps to allocate
bool find_adjoint(pugi::xml_node node)
{
	if (strcmp(node.name(), "Adjoint") == 0) {
		if (strcmp(node.attribute("type").value(), "steady") == 0) {
			return false;
		} else {
			return true;
		}
	} else return false;
}

// Main program function
int main ( int argc, char * argv[] )
{
	// Error handling for scanf
	#define HANDLE_IOERR(x) if ((x) == EOF) { error("Error in fscanf.\n"); return -1; }
	MPI_Init(&argc, &argv);

	Solver   solver(MPI_COMM_WORLD); // Global data declaration

	MPI_Comm_rank(MPI_COMM_WORLD,  &solver.mpi_rank);
	MPI_Comm_size(MPI_COMM_WORLD,  &solver.mpi_size);
	DEBUG_SETRANK(solver.mpi_rank);
	DEBUG_M;
	InitPrint(DEBUG_LEVEL, 6, 8);
	MPI_Barrier(MPI_COMM_WORLD);

	if (solver.mpi_rank == 0) {
		NOTICE("-------------------------------------------------------------------------\n");
		NOTICE("-  CLB version: %25s                               -\n",VERSION);
		NOTICE("-        Model: %25s                               -\n",MODEL);
		NOTICE("-------------------------------------------------------------------------\n");
	}
	MPI_Barrier(MPI_COMM_WORLD);
	DEBUG_M;

	DEBUG0(
	debug0("0 level debug");
	debug1("1 level debug");
	debug2("2 level debug");
	output("normal output");
	notice("notice");
	NOTICE("important notice");
	warning("warning");
	WARNING("important warning");
	error("error");
	ERROR("fatal error");
	)
	//Prepare MPI solver-structure
	solver.mpi.node = new NodeInfo[solver.mpi_size];
	solver.mpi.size = solver.mpi_size;
	solver.mpi.rank = solver.mpi_rank;
	solver.mpi.gpu = 0;
	for (int i=0;i < solver.mpi_size; i++) solver.mpi.node[i].rank = i;

	// Reading arguments
	// At least one argument
	if ( argc < 2 ) {
		error("Not enough parameters");
		notice("Usage: program configfile [device number]\n");
		return 0;
	}

	// After the configfile comes the numbers of GPU selected for each processor (starting with 0)
	{
		int count, dev;
		CudaGetDeviceCount( &count );
		if (argc >= 3) {
                	if (argc < 2 + solver.mpi.size) {
				error("Not enough device numbers");
				notice("Usage: program configfile [device number]\n");
				notice(" Provide device number for each processor (%d processors)\n", solver.mpi.size);
				return 0;
			}
			HANDLE_IOERR( sscanf(argv[2+solver.mpi.rank], "%d", &dev) );
			if (dev < 0) {
				error("Wrong device number: %s\n", argv[2+solver.mpi.rank]);
				return -1;
			}
			#ifdef GRAPHICS
				if (dev != 0) { error("Only device 0 can be selected for GUI program (not yet implemented)\n"); return -1; }
			#endif
		} else {
			CudaGetDeviceCount( &count );
			dev = solver.mpi.rank % count;
		}
		debug2("Selecting device %d/%d\n", dev, count);
		CudaSetDevice( dev );
		solver.mpi.gpu = dev;
	}
	MPI_Barrier(MPI_COMM_WORLD);
	DEBUG_M;

	// Calculating the right number of threads per block
	#ifdef CROSS_CPU
		solver.info.xsdim = 1;
		solver.info.ysdim = 1;
	#else
		solver.info.xsdim = 32;
		solver.info.ysdim = 1;
	#endif

	<?R for (tp in c("size_t","real_t","vector_t","flag_t")) { ?>
		debug0("sizeof(<?%s tp?>) = %ld\n", sizeof(<?%s tp?>));
	<?R } ?>
	MPI_Barrier(MPI_COMM_WORLD);

	// Reading the config file
	char* filename = argv[1];
	pugi::xml_document configfile;
        if (xml_def_init()) { error("Error in xml_def_init. It should work!\n"); return -1; }
	strcpy(solver.info.conffile, filename);
	solver.setOutput("");
	pugi::xml_parse_result result = configfile.load_file(filename);
	if (!result) {
		error("Error while parsing %s: %s\n", filename, result.description());
		return -1;
	}
	#define XMLCHILD(x,y,z) { x = y.child(z); if (!x) { error(" in %s: No \"%s\" element\n",filename,z); return -1; }}
	pugi::xml_node config, geom, units;
	XMLCHILD(config, configfile, "CLBConfig");
	XMLCHILD(geom, config, "Geometry");
	readUnits(config, &solver);

	// Reading the size of mesh
	int nx, ny, nz, ns = 2;
	nx = myround(solver.units.alt(geom.attribute("nx").value(),1));
	ny = myround(solver.units.alt(geom.attribute("ny").value(),1));
	nz = myround(solver.units.alt(geom.attribute("nz").value(),1));
	notice("Mesh size in config file: %dx%dx%d\n",nx,ny,nz);

	// Finding the adjoint element
	pugi::xml_node adj;
	adj = configfile.find_node(find_adjoint);
	if (adj) {
		pugi::xml_attribute attr = adj.attribute("NumberOfSnaps");
		if (attr) {
			ns = attr.as_int();
		} else {
			ns = 10;
		}
		if (ns < 2) ns =2;
		NOTICE("Will be running nonstationary adjoint at %d Snaps\n", D_MPI_RANK, ns);
	}

	// Initializing the lattice of a specific size
	if (solver.setSize(nx,ny,nz,ns)) return -1;

	// Initializing the CUDA events and setting callback
	CudaEventCreate( &start );
	CudaEventCreate( &stop );
	CudaEventRecord( start, 0 );
	solver.lattice->Callback((int(*)(int, void*)) MainCallback, (void*) &solver);

	// Running main handler (it makes all the magic)
	Handler hand(config, &solver);
	if (!hand) {
		error("Something went wrong in xml run!\n");
		return -1;
	}

	// Finish and clean up
	debug2("cudaFree ...\n");
	CudaEventDestroy( start );
	CudaEventDestroy( stop );
	MPI_Finalize();
	return 0;
}


