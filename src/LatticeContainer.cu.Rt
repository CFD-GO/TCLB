<?R
	source("conf.R")
        c_header()
?>
/** \file LatticeContainer.cu
  File defining LatticeContainer and some additional CUDA functions
*/

#include "Consts.h"
#include "Global.h"
#include "Lattice.h"
#include "mpi.h"

#define ALLOCPRINT1 printf("[%d] Allocating: %ld b ", D_MPI_RANK, size)
#define ALLOCPRINT2 printf("(%p - %p) \n", tmp, tmp+size)

int _xsdim = 0;
int _ysdim = 1;

/// Fast modulo for one k
CudaDeviceFunction inline int mymod(int x, int k){
        if (x >= k) return x-k;   
        if (x < 0) return x+k;
        return x;
}

/// Clear mem (unused)
CudaGlobalFunction void clearmem(real_t* ptr) {
	ptr[CudaBlock.x] = 0.0;
}

/// Init Settings with 0 in GPU constant memory
void initSettings() {
	real_t val = 0;
<?R for (v in rows(Settings)) {
	if (is.na(v$derived)) { ?>
			CudaCopyToConstant("<?%s v$name ?>", <?%s v$name ?>, &val, sizeof(real_t)); <?R
	}} ?>
}

/// Set Setting in GPU constant memory
/**
  Sets a Setting in the constant memory of GPU
  \param i Index of the Setting
  \param tmp value of the Setting
*/
void setConstSetting(int i, real_t tmp) {
	switch (i) {
<?R
        for (v in rows(Settings)) if (is.na(v$derived)) { ?>
	case <?%s v$Index ?>:
	        CudaCopyToConstant("<?%s v$name ?>", <?%s v$name ?>, &tmp, sizeof(real_t));
		break; <?R
        } ?>
	}
}

/// Get maximal number of threads for all the kernels on runtime
template <class N> dim3 GetThreads() {
	dim3 ret;
	CudaFuncAttributes * attr = new CudaFuncAttributes;
	CudaFuncGetAttributes(attr, RunKernel<N>) ;
	DEBUG1( printf( "[%d] Constant mem:%ld\n", D_MPI_RANK, attr->constSizeBytes) );
	DEBUG1( printf( "[%d] Local    mem:%ld\n", D_MPI_RANK, attr->localSizeBytes) );
	DEBUG1( printf( "[%d] Max  threads:%d\n", D_MPI_RANK, attr->maxThreadsPerBlock) );
	DEBUG1( printf( "[%d] Reg   Number:%d\n", D_MPI_RANK, attr->numRegs) );
	DEBUG1( printf( "[%d] Shared   mem:%ld\n", D_MPI_RANK, attr->sharedSizeBytes) );
	if (attr->maxThreadsPerBlock > MAX_THREADS) attr->maxThreadsPerBlock = MAX_THREADS;
	ret.x = X_BLOCK;
	ret.y = attr->maxThreadsPerBlock/ret.x;
	ret.z = 1;
	return ret;
}

/// Returns the number of blocks in Y direction
template < class N > inline int getKY() { return 0; }
/// Returns the number of threads in Y direction
template < class N > inline int getSY() { return 0; }

<?R for(tp in rows(Dispatch)) { ifdef(tp$adjoint_ver)
?>int kydim<?%s tp$suffix ?>, sydim<?%s tp$suffix ?>;
template < > inline int getKY< Node<?%s tp$suffix ?> >() { return kydim<?%s tp$suffix ?>; }
template < > inline int getSY< Node<?%s tp$suffix ?> >() { return sydim<?%s tp$suffix ?>; }
<?R }; ifdef();?>

/// Initialize Thread/Block number variables
int InitDim(int ny) {
	dim3 th; int ky;
	MPI_Barrier(MPI_COMM_WORLD);
	if (D_MPI_RANK == 0) {
          DEBUG2( printf( "[ ] |  Threads  |      Action  |\n") );
        }
	MPI_Barrier(MPI_COMM_WORLD);
<?R for(tp in rows(Dispatch)) { ifdef(tp$adjoint_ver)
?>	th = GetThreads< Node<?%s tp$suffix ?> >();
	DEBUG2( printf( "[%d] |  %3dx%-3d  |  %10s  |\n", D_MPI_RANK, th.x, th.y, "<?%s tp$suffix ?>") );
	MPI_Barrier(MPI_COMM_WORLD);
	sydim<?%s tp$suffix ?> = th.y;
	ky = ny/th.y;
	if (ky*th.y < ny) ky++;
	kydim<?%s tp$suffix ?> = ky;
<?R }; ifdef();
?>}

/// Allocation of a GPU memory Buffer
void * BAlloc(size_t size) {
  char * tmp;
    ALLOCPRINT1;
    #ifdef DIRECT_MEM
      CudaMallocHost( (void**)&tmp, size );
    #else
      CudaMalloc( (void**)&tmp, size );
    #endif
    ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
	return (void *) tmp;
}

/// Preallocation of a buffer (combines allocation into one big allocation)
void BPreAlloc(void ** ptr, size_t size) {
    CudaMalloc( ptr, size );
}

/// Allocation of memory for an FTabs
void FTabs::Alloc(int nx,int ny,int nz) {
  size_t size;
  char * tmp;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    ALLOCPRINT1;
    #ifdef DIRECT_MEM
      CudaMallocHost( (void**)&tmp, size );
    #else
      CudaMalloc( (void**)&tmp, size );
    #endif
    ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
    <?%s m$name ?>=  (real_t*)tmp;
  <?R } ?>
}

/// Preallocation of a FTabs
/**
  Aglomerates all the allocation into one big memory chunk
*/
void FTabs::PreAlloc(int nx,int ny,int nz) {
  size_t size;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    CudaPreAlloc( (void**)&<?%s m$name ?>, size );
  <?R } ?>
}

/// Clearing (zero-ing) of a FTabs
void FTabs::Clear(int nx,int ny,int nz) {
  size_t size;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    CudaMemset( <?%s m$name ?>, 0, size );
  <?R } ?>
}

/// NULL-safe free
inline void MyFree(void * ptr) {
    if (ptr != NULL) {
        #ifdef DIRECT_MEM
	    CudaFreeHost( ptr );
	#else
	    CudaFree( ptr );
	#endif
	ptr = NULL;
    }
}

/// Free FTabs memory
void FTabs::Free() { <?R
    for (m in NonEmptyMargin) { ?>
    MyFree(<?%s m$name ?>); 
    <?%s m$name ?> = NULL;<?R
    } ?>
}

/// Allocation of memory of a container
void LatticeContainer::Alloc(int nx_, int ny_, int nz_)
{
    iter = 0;
    nx = nx_;
    ny = ny_;
    nz = nz_;
    kx = nx/X_BLOCK;
    ky = ny;

    InitDim(ny);

    char * tmp;
    size_t size;

    size = (size_t) nx*ny*nz*sizeof(flag_t);
	ALLOCPRINT1;
    CudaMalloc( (void**)&tmp, size );
	ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
    NodeType = (flag_t*)tmp;

    size = (size_t) GLOBALS * sizeof(real_t);
	ALLOCPRINT1;
    CudaMalloc( (void**)&tmp, size );
	ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); // CudaKernelRun(clearmem,dim3(size/sizeof(real_t)),dim3(1),((real_t*)tmp));
    Globals = (real_t*)tmp;
}

/// Destroy Container
/**
  cannot do a constructor and destructor - because this class lives on GPU
*/
void LatticeContainer::Free()
{
    CudaFree( NodeType );
}


/// Push only parameters
template <class N> CudaDeviceFunction void LatticeContainer::push_param(N & node) 
{
<?R #	InOut("push", "out", Density, sel=Density$parameter); ?>
}

/// Push everything exept parameters
template <class N> CudaDeviceFunction void LatticeContainer::push_noparam(N & node) 
{
<?R #	InOut("push", "out", Density, sel=(! Density$parameter)); ?>
}

/// Get only type of node
template <class N> CudaDeviceFunction void LatticeContainer::getType(N & node) 
{
  node.NodeType = NodeType[(node.x + nx*node.y + nx*ny*node.z)];
        
<?R #	InOut("type", "in", Density); ?>
}

#ifdef ADJOINT
/// Push all adjoint densities
template <class N> CudaDeviceFunction void LatticeContainer::push_adj(N & node) 
{
<?R #	InOut("push", "adjout", DensityAD); ?>
}

/// Opposite of push_adj
template <class N> CudaDeviceFunction void LatticeContainer::pull_adj(N & node) 
{
<?R #	InOut("pull", "adjout", DensityAD); ?>
}

/// Get adjoint densities
template <class N> CudaDeviceFunction void LatticeContainer::pop_adj(N & node) 
{
<?R #	InOut("pop", "adjin", DensityAD); ?>
}
#endif

/// Push all densities

<?R
  MarginPocket = ""
  MarginPocketMove = FALSE
  
  set.buf = function(buf, pocket=FALSE) {
    if (missing(buf)) stop("No Buffor provided");
    if (pocket) {
      MarginPocket <<- "pocket" ?>
      FTabs <?%s MarginPocket ?> = <?%s buf ?>; <?R
      MarginPocketMove <<- TRUE
    } else {
      MarginPocket <<- buf
      MarginPocketMove <<- FALSE
    }
    clear.pocket()
  }
  
  clear.pocket = function() {
    for ( i in 1:length(Margin) ) Margin[[i]]$POffset <<- PV(0)
  }
  
  move.pocket = function(i,offset) {
      off = Margin[[i]]$POffset
      v = ToC(offset - off,float=F);
      if (v != "   0") { ?>
        <?%s MarginPocket?>.<?%s Margin[[i]]$name ?> += <?%s v ?>; <?R
      }
      Margin[[i]]$POffset <<- offset;
  }  
  
  if.apply = function(table, conditions, selection, fun) {
    n = length(conditions)
    if (ncol(table) != n) stop("number of columns in table should be equal to the number of conditions in if.apply")
    ord = do.call(order,data.frame(table))
    ord = ord[selection[ord]]
    req = function(j,l) {
#      cat("// j:",paste(j,collapse=","),l,"\n");
      if (l > n) {
        sapply(j,fun)
      } else {
        v = table[j,l]
#        cat("// v:",paste(v,collapse=","),"\n");
        sel1 = v == 1
        sel2 = v == -1
        sel3 = v == 0
        if (any(sel1)) { ?>
                 if (<?R C(conditions[l],float=F) ?> < 0) { <?R
          req(j[sel1],l+1);
          if (any(sel2)) {?>
                 } else { <?R
            req(j[sel2],l+1);
          } ?>
                 } <?R
        } else if (any(sel2)) { ?>
                 if (<?R C(conditions[l],float=F) ?> >= 0) { <?R
          req(j[sel2],l+1); ?>
                 } <?R
        }
        if (any(sel3)) {
          req(j[sel3],l+1);
        }
      }
    }
    req(ord,1)
  }

#  No x move:
  no.x.move = TRUE
     
  load.field = function(d,f,p,dp) {
    ret = f$get_offsets(p,dp)
    if (MarginPocketMove) for (m in 1:27) if (ret$Selection[m]) {
      if (no.x.move) {
        move.pocket(m, subst(ret$Offset[m],p[1]==-dp[1]))
      } else {
        move.pocket(m, ret$Offset[m])
      }
    }
    if.apply(ret$Table,ret$Conditions,ret$Selection,function(m) {
      ?>
     <?%s d ?> = <?%s MarginPocket ?>.<?%s Margin[[m]]$name ?>[<?R C(ret$Offset[m] - Margin[[m]]$POffset,float=F) ?>]; <?R
    })
  }

  save.field = function(d,f,p) {
    ret = f$put_offsets(p)
    if (MarginPocketMove) for (m in 1:27) if (ret$Selection[m]) {
      if (no.x.move) {
        move.pocket(m, subst(ret$Offset[m],p[1]==0))
      } else {
        move.pocket(m, ret$Offset[m])
      }
    }
    if.apply(ret$Table,ret$Conditions,ret$Selection,function(m) {
      ?>
     <?%s MarginPocket ?>.<?%s Margin[[m]]$name ?>[<?R C(ret$Offset[m] - Margin[[m]]$POffset,float=F) ?>] = <?%s d ?>; <?R
    })
  }

?>

template <class N> CudaDeviceFunction void LatticeContainer::pop(N & node) 
{
<?R
  set.buf("in",pocket=TRUE);
  for (d in rows(Density)) { ?>
//--------------------------- <?%s d$name ?> ----------------------<?R
    f = Fields[[d$field]]
    p = PV(c("node.x","node.y","node.z"));
    dp = c(-d$dx, -d$dy, -d$dz)
    load.field(paste("node",d$name,sep="."), f, p, dp)
  }?>
}

template <class N> CudaDeviceFunction void LatticeContainer::pull(N & node) 
{
<?R
  set.buf("in",pocket=TRUE);
  for (d in rows(Density)) { ?>
//--------------------------- <?%s d$name ?> ----------------------<?R
    f = Fields[[d$field]]
    p = PV(c("node.x","node.y","node.z"));
    dp = c(-d$dx, -d$dy, -d$dz)
    load.field(paste("node",d$name,sep="."), f, p, dp)
  }?>
}


<?R
  for (f in Fields) { ?>
//template <int dx, int dy, int dz>
//CudaDeviceFunction real_t& LatticeContainer::load_<?%s f$nicename ?> (const int & x, const int & y, const int & z) ; <?R
  }
?>

<?R
  for (f in Fields) { 
    for (dx in f$minx:f$maxx) for (dy in f$miny:f$maxy) for (dz in f$minz:f$maxz) { ?>
template <> CudaDeviceFunction real_t& LatticeContainer::load_<?%s f$nicename ?> < <?%d dx ?>, <?%d dy ?>, <?%d dz ?> > (const int & x, const int & y, const int & z) 
{
  real_t ret; <?R
  set.buf("in");
  p = PV(c("x","y","z"));
  dp = c(dx, dy, dz)
  load.field("ret", f, p, dp) ?>
  return ret;
}
<?R }} ?>


template <class N> CudaDeviceFunction void LatticeContainer::push(N & node) 
{
<?R
  set.buf("out",pocket=TRUE);
  for (f in Fields) { ?>
//--------------------------- <?%s f$name ?> ----------------------<?R
    p = PV(c("node.x","node.y","node.z"));
    save.field(paste("node",f$name,sep="."), f, p)
  }?>
}


/// Main Kernel
/**
  iterates over all elements and runs them with RunElement function.
  constContainer.dx/dy is to calculate only internal nodes
*/
template <class N> CudaGlobalFunction void RunKernel()
{
	N now;
	now.x = CudaThread.x+CudaBlock.z*CudaNumberOfThreads.x+constContainer.dx;
	now.y = CudaThread.y+CudaBlock.x*CudaNumberOfThreads.y+constContainer.dy;
	now.z = CudaBlock.y+constContainer.dz;
	#ifndef GRID_3D
		for (; now.x < constContainer.nx; now.x += CudaNumberOfThreads.x) {
	#endif
		now.Pre();
		if (now.y < constContainer.fy) {
			now.RunElement();
		}
		now.Glob();
	#ifndef GRID_3D
		}
	#endif
}

/// BORDER_Z defines if we need to take Z direction in consiredation border/interior
//   if a model is 2D everything in the Z direction is interior
<?R if (any(DensityAll$dz != 0)) {?>
#define BORDER_Z // The model is 3D
<?R } else { ?>
// The model is 2D (no BORDER_Z)
<?R } ?>

/*
// Border Kernel
//   iterates over border elements and runs them with RunElement function
template <class N> CudaGlobalFunction void RunBorderKernel()
{
	N now;
	now.x = CudaThread.x + CudaBlock.y*X_BLOCK;
	now.z = CudaBlock.x;
	now.Pre();
#ifdef BORDER_Z
	if (now.z < constContainer.nz) {
#endif
		now.y = 0;
		now.RunElement();
#ifdef BORDER_Z
	}
#endif
	now.Glob();
	now.Pre();
#ifdef BORDER_Z
	if (now.z < constContainer.nz) {
#endif
		now.y = constContainer.ny - 1;
		now.RunElement();
#ifdef BORDER_Z
	}
#endif
	now.Glob();
	now.Pre();
#ifdef BORDER_Z
	now.y = CudaBlock.x;
	if ((now.y < constContainer.ny-1) && (now.y > 0)) {
		now.z = 0;
                now.RunElement();
	}
	now.Glob();
	now.Pre();
	if ((now.y < constContainer.ny-1) && (now.y > 0)) {
                now.z = constContainer.nz - 1;
                now.RunElement();
	}
	now.Glob();
#endif
}
*/

/// Border Kernel
/**
  iterates over border elements and runs them with RunElement function
*/
template <class N> CudaGlobalFunction void RunBorderKernel()
{
	N now;
	now.x = CudaThread.x + CudaBlock.y*X_BLOCK;
	now.z = CudaBlock.x;
	now.Pre();
#ifdef BORDER_Z
	if (now.z < constContainer.nz) {
#endif
		now.y = 0;
		now.RunElement();
		now.y = constContainer.ny - 1;
		now.RunElement();
#ifdef BORDER_Z
	}
	now.y = CudaBlock.x;
	if ((now.y < constContainer.ny-1) && (now.y > 0)) {
		now.z = 0;
                now.RunElement();
                now.z = constContainer.nz - 1;
                now.RunElement();
	}
	now.Glob();
#endif
}

/// Copy oneself to the GPU constant memory
/**
  Copiers the container object to constContainer variable
  in the constant memory of the GPU
*/
void LatticeContainer::CopyToConst() {
    fx=nx;
    fy=ny-1;
    dx = 0; dy = 1; 
    #ifdef BORDER_Z
	dz = 1;
	fz = nz - 1;
    #else
	dz = 0;
	fz = nz;
    #endif
    CudaCopyToConstant("constContainer", constContainer, this, sizeof(LatticeContainer));
}

/// Run the border kernel
/**
  Dispatch the kernel running RunElement on all border elements of the Lattice
  \param borderStream CUDA Stream to which add the kernel run
*/
template <class N> inline void LatticeContainer::RunBorderT(CudaStream_t borderStream) {
    #ifdef BORDER_Z
	    CudaKernelRunNoWait( RunBorderKernel<N> , dim3(max(ny,nz),kx,1) , dim3(X_BLOCK),(),borderStream);
    #else
	    CudaKernelRunNoWait( RunBorderKernel<N> , dim3(nz,kx,1) , dim3(X_BLOCK),(),borderStream);
    #endif
};

/// Run the interior kernel
/**
  Dispatch the kernel running RunElement on all interior elements of the lattice
  \param interiorStream CUDA Stream to which add the kernel run
*/
template <class N> inline void LatticeContainer::RunInteriorT(CudaStream_t interiorStream) {
    int nnz;
    ky = getKY<N>();
    #ifdef BORDER_Z
	nnz = nz - 2;
    #else
	nnz = nz;
    #endif
    #ifdef GRID_3D
        CudaKernelRunNoWait( RunKernel<N> , dim3(ky, nnz, kx) , dim3(X_BLOCK,getSY<N>()),(),interiorStream);
    #else
        CudaKernelRunNoWait( RunKernel<N> , dim3(ky, nnz, 1) , dim3(X_BLOCK,getSY<N>()),(),interiorStream);
    #endif
};

// Type specific runs (template specializations)
<?R for(tp in rows(Dispatch)) {
ifdef(tp$adjoint_ver) ?>
/// Runs a Node_<?%s tp$suffix ?> dynamics on all border nodes
void LatticeContainer::RunBorder<?%s tp$suffix ?>(CudaStream_t stream)   { RunBorderT< Node<?%s tp$suffix ?> >(stream); };

/// Runs a Node_<?%s tp$suffix ?> dynamics on all interior nodes
void LatticeContainer::RunInterior<?%s tp$suffix ?>(CudaStream_t stream) { RunInteriorT< Node<?%s tp$suffix ?> >(stream); };
<?R }
ifdef(); ?>
 
/// Old function for graphics output
/**
  calculates the color for one node
*/
CudaDeviceFunction void NodeToColor( int x, int y, int z, uchar4 *optr )
{
    int offset = x+y*constContainer.nx;
    float l=0.0; float w=0.0;
    int r=0,g=0,b=0;
    Node now;
    now.x = x;
    now.y = y;
    now.z = z;
    constContainer.pull(now);
    {
     float2 v = now.Color();
     l = v.x;
     w = v.y;
    }

if (isfinite(l)) {

    l = l * 111;
    if (               (l <-111)) {r = 255; g = 255; b = 255; }
    if ((l >= -111) && (l < -11)) {r = 255*(-l-11)/100; g = 255; b = 255; }
    if ((l >=  -11) && (l <  -1)) {r = 0; g = (255*(-l-1))/10; b = 255; }
    if ((l >=   -1) && (l <   0)) {r = 0; g = 0; b = 255*(-l); }
    if ((l >=    0) && (l <   1)) {r = 255*l; g = 0; b = 0; }
    if ((l >=    1) && (l <  11)) {r = 255; g = 255*(l-1)/10; b = 0; }
    if ((l >=   11) && (l < 111)) {r = 255; g = 255; b = 255*(l-11)/100; }
    if ((l >=  111)             ) {r = 255; g = 255; b = 255; }
    r=r*w;
    g=g*w + (1-w)*255;
    b=b*w;
} else {
    r=255;
    b=255;
    g=0;
}
    optr[offset].x = r;  
    optr[offset].y = g;  
    optr[offset].z = b;  
    optr[offset].w = 255;
}

/// Kernel for graphics output
CudaGlobalFunction void ColorKernel( uchar4 *optr, int z )
{
  NodeToColor(
    CudaThread.x+CudaBlock.x*CudaNumberOfThreads.x,
    CudaBlock.y,
    z,
    optr
  );
}

/// Runs kernel for rendering graphics
/**
  Runs the kernel for rendering graphics 
  \param optr 4-component graphics buffer
*/
void LatticeContainer::Color( uchar4 *optr ) {
   CudaCopyToConstant("constContainer", constContainer, this, sizeof(LatticeContainer));	
   CudaKernelRun( ColorKernel , dim3(kx,ny,1), dim3(X_BLOCK) ,(optr, nz/2));
};

// Functions for getting quantities
<?R
        for (q in rows(Quantities))
        {
                ifdef(q$adjoint); ?>
/// Calculate quantity [<?%s q$comment ?>] kernel
/**
  Kernel to calculate quantity <?%s q$name ?> (<?%s q$comment ?>) over a region
  \param r Lattice region to calculate the quantity
  \param tab buffor to put the calculated result
  \param scale Scale to rescale the result (for units)
*/
CudaGlobalFunction void get<?%s q$name ?>(lbRegion r, <?%s q$type ?> * tab, real_t scale)
{
	int x = CudaBlock.x+r.dx;
	int y = CudaBlock.y+r.dy; <?R
	if (q$adjoint) { ?>
	Node_Adj now; <?R
        } else { ?>
	Node now; <?R
        } ?>
	int z;
	for (z = r.dz; z < r.dz + r.nz; z ++) {
		now.x = x;
		now.y = y;
		now.z = z;
		constContainer.pull(now); <?R
		if (q$adjoint) { ?>
		constContainer.pull_adj(now); <?R
                } ?>
		<?%s q$type ?> w = now.get<?%s q$name ?>(); <?R
		if (q$type == "vector_t")
		{
                  for (coef in c("x","y","z")) { ?>
		w.<?%s coef ?> *= scale; <?R
		  }
		} else { ?>
		w *= scale; <?R
                } ?>
		tab[r.offset(x,y,z)] = w;
	}
}
<?R
        }
        ifdef();
?>

