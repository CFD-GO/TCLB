<?R
	source("conf.R")
        c_header()
?>
/** \file LatticeContainer.cu
  File defining LatticeContainer and some additional CUDA functions
*/

#include "Consts.h"
#include "Global.h"
#include "Lattice.h"
#include "mpi.h"
#define ALLOCPRINT1 debug2("Allocating: %ld b\n", size)
#define ALLOCPRINT2 debug1("got address: (%p - %p)\n", tmp, tmp+size)

int _xsdim = 0;
int _ysdim = 1;

/// Fast modulo for one k
CudaDeviceFunction inline int mymod(int x, int k){
        if (x >= k) return x-k;   
        if (x < 0) return x+k;
        return x;
}

/// Clear mem (unused)
CudaGlobalFunction void clearmem(real_t* ptr) {
	ptr[CudaBlock.x] = 0.0;
}

/// Init Settings with 0 in GPU constant memory
void initSettings() {
	real_t val = 0;
<?R for (v in rows(Settings)) {
	if (is.na(v$derived)) { ?>
			CudaCopyToConstant("<?%s v$name ?>", <?%s v$name ?>, &val, sizeof(real_t)); <?R
	}} ?>
}

/// Set Setting in GPU constant memory
/**
  Sets a Setting in the constant memory of GPU
  \param i Index of the Setting
  \param tmp value of the Setting
*/
void setConstSetting(int i, real_t tmp) {
	switch (i) {
<?R
        for (v in rows(Settings)) if (is.na(v$derived)) { ?>
	case <?%s v$Index ?>:
	        CudaCopyToConstant("<?%s v$name ?>", <?%s v$name ?>, &tmp, sizeof(real_t));
		break; <?R
        } ?>
	}
}

/// Get maximal number of threads for all the kernels on runtime
template < class N > dim3 GetThreads() {
	dim3 ret;
	CudaFuncAttributes * attr = new CudaFuncAttributes;
	CudaFuncGetAttributes(attr, RunKernel<N>) ;
	debug1( "[%d] Constant mem:%ld\n", D_MPI_RANK, attr->constSizeBytes);
	debug1( "[%d] Local    mem:%ld\n", D_MPI_RANK, attr->localSizeBytes);
	debug1( "[%d] Max  threads:%d\n", D_MPI_RANK, attr->maxThreadsPerBlock);
	debug1( "[%d] Reg   Number:%d\n", D_MPI_RANK, attr->numRegs);
	debug1( "[%d] Shared   mem:%ld\n", D_MPI_RANK, attr->sharedSizeBytes);
	if (attr->maxThreadsPerBlock > MAX_THREADS) attr->maxThreadsPerBlock = MAX_THREADS;
	ret.x = X_BLOCK;
	ret.y = attr->maxThreadsPerBlock/ret.x;
	ret.z = 1;
	return ret;
}


template < class N > class ThreadNumber {
  public:
  static unsigned int ky, sy;
  static void Init(size_t ny) {
	dim3 th = GetThreads< N >();
	sy = th.y;
	ky = ny/th.y;
	if (ky*th.y < ny) ky++;
  }
  static inline int getKY() { return ky; }
  static inline int getSY() { return sy; }
};

template < class N > unsigned int ThreadNumber< N >::ky = 0;
template < class N > unsigned int ThreadNumber< N >::sy = 0;
  
/// Initialize Thread/Block number variables
int InitDim(int ny) {
	MPI_Barrier(MPI_COMM_WORLD);
<?R	for (tp in rows(AllKernels)[order(AllKernels$adjoint)]) { ifdef(tp$adjoint) ?>
        ThreadNumber< Node_Run< <?%s tp$TemplateArgs ?> > >::Init(ny); <?R
	}; ifdef(); ?>
	MPI_Barrier(MPI_COMM_WORLD);
	if (D_MPI_RANK == 0) {
          debug2( "  Threads  |      Action\n");
        }
<?R	for (tp in rows(AllKernels)) { ifdef(tp$adjoint) ?>
	debug2( "  %3dx%-3d  | %s\n", X_BLOCK, ThreadNumber< Node_Run< <?%s tp$TemplateArgs ?> > >::getSY(), "<?%s tp$TemplateArgs ?>");<?R
	}; ifdef();
?>
        return 0;
}

/// Allocation of a GPU memory Buffer
void * BAlloc(size_t size) {
  char * tmp = NULL;
    ALLOCPRINT1;
    #ifdef DIRECT_MEM
      CudaMallocHost( (void**)&tmp, size );
    #else
      CudaMalloc( (void**)&tmp, size );
    #endif
    ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
	return (void *) tmp;
}

/// Preallocation of a buffer (combines allocation into one big allocation)
void BPreAlloc(void ** ptr, size_t size) {
    CudaMalloc( ptr, size );
}

/// Allocation of memory for an FTabs
void FTabs::Alloc(int nx,int ny,int nz) {
  size_t size;
  char * tmp = NULL;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    ALLOCPRINT1;
    #ifdef DIRECT_MEM
      CudaMallocHost( (void**)&tmp, size );
    #else
      CudaMalloc( (void**)&tmp, size );
    #endif
    ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
    <?%s m$name ?>=  (real_t*)tmp;
  <?R } ?>
}

/// Preallocation of a FTabs
/**
  Aglomerates all the allocation into one big memory chunk
*/
void FTabs::PreAlloc(int nx,int ny,int nz) {
  size_t size;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    CudaPreAlloc( (void**)&<?%s m$name ?>, size );
  <?R } ?>
}

/// Clearing (zero-ing) of a FTabs
void FTabs::Clear(int nx,int ny,int nz) {
  size_t size;
  <?R for (m in NonEmptyMargin) { ?>
    size = (size_t) <?R C(m$Size,float=F) ?>*sizeof(real_t);
    CudaMemset( <?%s m$name ?>, 0, size );
  <?R } ?>
}

/// NULL-safe free
inline void MyFree(void * ptr) {
    if (ptr != NULL) {
        #ifdef DIRECT_MEM
	    CudaFreeHost( ptr );
	#else
	    CudaFree( ptr );
	#endif
	ptr = NULL;
    }
}

/// Free FTabs memory
void FTabs::Free() { <?R
    for (m in NonEmptyMargin) { ?>
    MyFree(<?%s m$name ?>); 
    <?%s m$name ?> = NULL;<?R
    } ?>
}

/// Allocation of memory of a container
void LatticeContainer::Alloc(int nx_, int ny_, int nz_)
{
    iter = 0;
    nx = nx_;
    ny = ny_;
    nz = nz_;
    kx = nx/X_BLOCK;
    ky = ny;

    InitDim(ny);

    char * tmp=NULL;
    size_t size;

    size = (size_t) nx*ny*nz*sizeof(flag_t);
	ALLOCPRINT1;
    CudaMalloc( (void**)&tmp, size );
	ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); 
    NodeType = (flag_t*)tmp;

    Q = NULL;

    size = (size_t) GLOBALS * sizeof(real_t);
	ALLOCPRINT1;
    CudaMalloc( (void**)&tmp, size );
	ALLOCPRINT2;
    CudaMemset( tmp, 0, size ); // CudaKernelRun(clearmem,dim3(size/sizeof(real_t)),dim3(1),((real_t*)tmp));
    Globals = (real_t*)tmp;
	ST.setsize(0, ST_GPU);
}

void LatticeContainer::ActivateCuts() {
    if (Q == NULL) {
            void * tmp;
            size_t size = (size_t) nx*ny*nz*sizeof(cut_t)*26;
                ALLOCPRINT1;
            CudaMalloc( (void**)&tmp, size );
                ALLOCPRINT2;
            CudaMemset( tmp, 0, size ); 
            Q = (cut_t*)tmp;
    }
}

/// Destroy Container
/**
  cannot do a constructor and destructor - because this class lives on GPU
*/
void LatticeContainer::Free()
{
    CudaFree( NodeType );
    if (Q != NULL) CudaFree( Q ); 
}


/// Main Kernel
/**
  iterates over all elements and runs them with RunElement function.
  constContainer.dx/dy is to calculate only internal nodes
*/
template <class N> CudaGlobalFunction void RunKernel()
{
	N now;
	now.x_ = CudaThread.x+CudaBlock.z*CudaNumberOfThreads.x+constContainer.dx;
	now.y_ = CudaThread.y+CudaBlock.x*CudaNumberOfThreads.y+constContainer.dy;
	now.z_ = CudaBlock.y+constContainer.dz;
	#ifndef GRID_3D
		for (; now.x_ < constContainer.nx; now.x_ += CudaNumberOfThreads.x) {
	#endif
		now.Pre();
		if (now.y_ < constContainer.fy) {
			now.RunElement();
		} else {
			now.OutOfDomain();
		}
		now.Glob();
	#ifndef GRID_3D
		}
	#endif
}

/// BORDER_Z defines if we need to take Z direction in consiredation border/interior
//   if a model is 2D everything in the Z direction is interior
<?R if (any(DensityAll$dz != 0)) {?>
#define BORDER_Z // The model is 3D
<?R } else { ?>
// The model is 2D (no BORDER_Z)
<?R } ?>

/*
// Border Kernel
//   iterates over border elements and runs them with RunElement function
template <class N> CudaGlobalFunction void RunBorderKernel()
{
	N now;
	now.x_ = CudaThread.x + CudaBlock.y*X_BLOCK;
	now.z_ = CudaBlock.x;
	now.Pre();
#ifdef BORDER_Z
	if (now.z_ < constContainer.nz) {
#endif
		now.y_ = 0;
		now.RunElement();
#ifdef BORDER_Z
	}
#endif
	now.Glob();
	now.Pre();
#ifdef BORDER_Z
	if (now.z_ < constContainer.nz) {
#endif
		now.y_ = constContainer.ny - 1;
		now.RunElement();
#ifdef BORDER_Z
	}
#endif
	now.Glob();
	now.Pre();
#ifdef BORDER_Z
	now.y_ = CudaBlock.x;
	if ((now.y_ < constContainer.ny-1) && (now.y_ > 0)) {
		now.z_ = 0;
                now.RunElement();
	}
	now.Glob();
	now.Pre();
	if ((now.y_ < constContainer.ny-1) && (now.y_ > 0)) {
                now.z_ = constContainer.nz - 1;
                now.RunElement();
	}
	now.Glob();
#endif
}
*/

/// Border Kernel
/**
  iterates over border elements and runs them with RunElement function
*/
template <class N> CudaGlobalFunction void RunBorderKernel()
{
	N now;
	now.x_ = CudaThread.x + CudaBlock.y*X_BLOCK;
	now.z_ = CudaBlock.x;
	now.Pre();
#ifdef BORDER_Z
	if (now.z_ < constContainer.nz) {
#endif
		now.y_ = 0;
		now.RunElement();
		now.y_ = constContainer.ny - 1;
		now.RunElement();
#ifdef BORDER_Z
	}
	now.y_ = CudaBlock.x;
	if ((now.y_ < constContainer.ny-1) && (now.y_ > 0)) {
		now.z_ = 0;
                now.RunElement();
                now.z_ = constContainer.nz - 1;
                now.RunElement();
	}
#endif
	now.Glob();
}

/// Copy oneself to the GPU constant memory
/**
  Copiers the container object to constContainer variable
  in the constant memory of the GPU
*/
void LatticeContainer::CopyToConst() {
    fx=nx;
    fy=ny-1;
    dx = 0; dy = 1; 
    #ifdef BORDER_Z
	dz = 1;
	fz = nz - 1;
    #else
	dz = 0;
	fz = nz;
    #endif
    CudaCopyToConstant("constContainer", constContainer, this, sizeof(LatticeContainer));
}

/// Run the border kernel
/**
  Dispatch the kernel running RunElement on all border elements of the Lattice
  \param borderStream CUDA Stream to which add the kernel run
*/
template <class N> inline void LatticeContainer::RunBorderT(CudaStream_t borderStream) {
    #ifdef BORDER_Z
	    CudaKernelRunNoWait( RunBorderKernel<N> , dim3(max(ny,nz),kx,1) , dim3(X_BLOCK),(),borderStream);
    #else
	    CudaKernelRunNoWait( RunBorderKernel<N> , dim3(nz,kx,1) , dim3(X_BLOCK),(),borderStream);
    #endif
};

/// Run the interior kernel
/**
  Dispatch the kernel running RunElement on all interior elements of the lattice
  \param interiorStream CUDA Stream to which add the kernel run
*/
template <class N> inline void LatticeContainer::RunInteriorT(CudaStream_t interiorStream) {
    int nnz;
    ky = ThreadNumber< N >::getKY();
    #ifdef BORDER_Z
	nnz = nz - 2;
    #else
	nnz = nz;
    #endif
    #ifdef GRID_3D
        CudaKernelRunNoWait( RunKernel<N> , dim3(ky, nnz, kx) , dim3(X_BLOCK,ThreadNumber< N >::getSY()),(),interiorStream);
    #else
        CudaKernelRunNoWait( RunKernel<N> , dim3(ky, nnz, 1) , dim3(X_BLOCK,ThreadNumber< N >::getSY()),(),interiorStream);
    #endif
};

template < eOperationType I, eCalculateGlobals G, eStage S >
  void LatticeContainer::RunBorder(CudaStream_t stream)   { RunBorderT< Node_Run < I, G, S > >(stream); };

template < eOperationType I, eCalculateGlobals G, eStage S >
  void LatticeContainer::RunInterior(CudaStream_t stream) { RunInteriorT< Node_Run < I, G, S > >(stream); };
  
/// Old function for graphics output
/**
  calculates the color for one node
*/
template <class N>
CudaDeviceFunction void NodeToColor( int x, int y, int z, uchar4 *optr )
{
    int offset = x+y*constContainer.nx;
    float l=0.0; float w=0.0;
    int r=0,g=0,b=0;
    N now;
    if (x < 0) return;
    if (y < 0) return;
    if (z < 0) return;
    if (x >= constContainer.nx) return;
    if (y >= constContainer.ny) return;
    if (z >= constContainer.nz) return;
    now.x_ = x;
    now.y_ = y;
    now.z_ = z;
    constContainer.getType(now);
    constContainer.pop(now);
    {
     float2 v = now.Color();
     l = v.x;
     w = v.y;
    }

if (ISFINITE(l)) {

    l = l * 111;
    if (               (l <-111)) {r = 255; g = 255; b = 255; }
    if ((l >= -111) && (l < -11)) {r = 255*(-l-11)/100; g = 255; b = 255; }
    if ((l >=  -11) && (l <  -1)) {r = 0; g = (255*(-l-1))/10; b = 255; }
    if ((l >=   -1) && (l <   0)) {r = 0; g = 0; b = 255*(-l); }
    if ((l >=    0) && (l <   1)) {r = 255*l; g = 0; b = 0; }
    if ((l >=    1) && (l <  11)) {r = 255; g = 255*(l-1)/10; b = 0; }
    if ((l >=   11) && (l < 111)) {r = 255; g = 255; b = 255*(l-11)/100; }
    if ((l >=  111)             ) {r = 255; g = 255; b = 255; }
    r=r*w;
    g=g*w + (1-w)*255;
    b=b*w;
} else {
    r=255;
    b=255;
    g=0;
}
    optr[offset].x = r;  
    optr[offset].y = g;  
    optr[offset].z = b;  
    optr[offset].w = 255;
}

/// Kernel for graphics output
CudaGlobalFunction void ColorKernel( uchar4 *optr, int z )
{
  NodeToColor< Node_Run< Primal, NoGlobals, Get > >(
    CudaThread.x+CudaBlock.x*CudaNumberOfThreads.x,
    CudaBlock.y,
    z,
    optr
  );
}

/// Runs kernel for rendering graphics
/**
  Runs the kernel for rendering graphics 
  \param optr 4-component graphics buffer
*/
void LatticeContainer::Color( uchar4 *optr ) {
   CudaCopyToConstant("constContainer", constContainer, this, sizeof(LatticeContainer));	
   CudaKernelRun( ColorKernel , dim3(kx,ny,1), dim3(X_BLOCK) ,(optr, nz/2));
};

// Functions for getting quantities
<?R
        for (q in rows(Quantities))
        {
                ifdef(q$adjoint); ?>
/// Calculate quantity [<?%s q$comment ?>] kernel
/**
  Kernel to calculate quantity <?%s q$name ?> (<?%s q$comment ?>) over a region
  \param r Lattice region to calculate the quantity
  \param tab buffor to put the calculated result
  \param scale Scale to rescale the result (for units)
*/
CudaGlobalFunction void get<?%s q$name ?>(lbRegion r, <?%s q$type ?> * tab, real_t scale)
{
	int x = CudaBlock.x+r.dx;
	int y = CudaBlock.y+r.dy; <?R
        if (q$adjoint) { ?>
          Node_Run< Adjoint, NoGlobals, Get > now; <?R
        } else { ?>
          Node_Run< Primal, NoGlobals, Get > now; <?R
        }?>
	int z;
	for (z = r.dz; z < r.dz + r.nz; z ++) {
		now.x_ = x;
		now.y_ = y;
		now.z_ = z;
		constContainer.getType(now);
		<?%s q$type ?> w;
//		if (now.NodeType) {
			constContainer.pop(now); <?R
			if (q$adjoint) { ?>
			constContainer.pop_adj(now); <?R
	                } ?>
			w = now.get<?%s q$name ?>(); <?R
			if (q$type == "vector_t") {
	                  for (coef in c("x","y","z")) { ?>
			w.<?%s coef ?> *= scale; <?R
			  }
			} else { ?>
			w *= scale; <?R
	                } ?>
//		} else { <?R
			if (q$type == "vector_t") {
	                  for (coef in c("x","y","z")) { ?>
//			w.<?%s coef ?> = nan(""); <?R
			  }
			} else { ?>
//			w = nan(""); <?R
	                } ?>
//		}
		tab[r.offset(x,y,z)] = w;
	}
}
<?R
        }
        ifdef();
?>


<?R     for (tp in rows(AllKernels)[order(AllKernels$adjoint)]) { ifdef(tp$adjoint) ?>
template void LatticeContainer::RunBorder < <?%s tp$TemplateArgs ?> > (CudaStream_t stream);
template void LatticeContainer::RunInterior < <?%s tp$TemplateArgs ?> > (CudaStream_t stream); <?R
         }; ifdef(); ?>
