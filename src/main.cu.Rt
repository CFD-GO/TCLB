<?R
        source("conf.R")
	c_header();
?>

//#include "pugixml.hpp"
#include "Global.h"
#include <mpi.h>
#ifdef GRAPHICS
	#include "gpu_anim.h"
#endif
//#include "cross.h"
#include "Region.h"
//#include "Node.h"
//#include "LatticeContainer.h"
//#include "Lattice.h"
//#include "vtkLattice.h"
//#include "Geometry.h"
//#include "def.h"
#include "utils.h"
#include "unit.h"

#include <fstream>
#include <iostream>
#include <vector>
#include <iomanip>
#include <assert.h>

#include "Solver.h"


// main program function
int main ( int argc, char * argv[] )
{
	// Error handling for scanf
	#define HANDLE_IOERR(x) if ((x) == EOF) { fprintf(stderr, "[%d] Error in fscanf.\n", D_MPI_RANK); return -1; }

	MPI_Init(&argc, &argv);

	Solver   solver(MPI_COMM_WORLD); // Global data declaration


	MPI_Comm_rank(MPI_COMM_WORLD,  &solver.mpi_rank);
	MPI_Comm_size(MPI_COMM_WORLD,  &solver.mpi_size);
	DEBUG_SETRANK(solver.mpi_rank);
	DEBUG_M;
	MPI_Barrier(MPI_COMM_WORLD);
	if (solver.mpi_rank == 0) {
		printf("[ ] -------------------------------------------------------------------------\n");
		printf("[ ] -  CLB version: %25s                               -\n",VERSION);
		printf("[ ] -        Model: %25s                               -\n",MODEL);
		printf("[ ] -------------------------------------------------------------------------\n");
	}
	MPI_Barrier(MPI_COMM_WORLD);
	DEBUG_M;

	//Prepare MPI solver-structure
	solver.mpi.node = new NodeInfo[solver.mpi_size];
	solver.mpi.size = solver.mpi_size;
	solver.mpi.rank = solver.mpi_rank;
	solver.mpi.gpu = 0;
	for (int i=0;i < solver.mpi_size; i++) solver.mpi.node[i].rank = i;


	// Reading arguments
	// At least one argument
	if ( argc < 2 ) {
		fprintf(stderr, "Usage: program configfile [device number]\n");
		return 0;
	}

	// After the configfile comes the numbers of GPU selected for each processor (starting with 0)
	{
		int count, dev;
		CudaGetDeviceCount( &count );
		if (argc >= 3) {
                	if (argc < 2 + solver.mpi.size) {
				fprintf(stderr, "Usage: program configfile [device number]\n");
				fprintf(stderr, " Provide device number for each processor (%d processors)\n", solver.mpi.size);
				return 0;
			}
			HANDLE_IOERR( sscanf(argv[2+solver.mpi.rank], "%d", &dev) );
			if (dev < 0) {
				fprintf(stderr, "Wrong device number: %s\n", argv[2+solver.mpi.rank]);
				return -1;
			}
			#ifdef GRAPHICS
				if (dev != 0) { fprintf(stderr, "Only device 0 can be selected for GUI program (not yet implemented)\n"); return -1; }
			#endif
		} else {
			CudaGetDeviceCount( &count );
			dev = solver.mpi.rank % count;
		}
		printf("[%d] Selecting device %d/%d\n", solver.mpi.rank, dev, count);
		CudaSetDevice( dev );
		solver.mpi.gpu = dev;		
	}

	MPI_Barrier(MPI_COMM_WORLD);
	DEBUG_M;

	// Calculating the right number of threads per block
	#ifdef CROSS_CPU
		solver.info.xsdim = 1;
		solver.info.ysdim = 1;
	#else
		solver.info.xsdim = 32;
		solver.info.ysdim = 1;
	#endif

	// 1024 threads not working. (Why?)
	if (solver.info.xsdim > 512) solver.info.xsdim = 512;

	printf("[%d] Running at %dx%d threads per block\n", D_MPI_RANK, solver.info.xsdim, solver.info.ysdim);
	MPI_Barrier(MPI_COMM_WORLD);
	<?R for (tp in c("size_t","real_t","vector_t","flag_t")) { ?>
		printf("[%d] sizeof(<?%s tp?>) = %ld\n", D_MPI_RANK, sizeof(<?%s tp?>));
	<?R } ?>
	MPI_Barrier(MPI_COMM_WORLD);

	// Reading the config file
	char* filename = argv[1];
	if (solver.readConf(filename)) return -1;

	if (solver.loadSize()) return -1;

	if (solver.MPIDivision()) return -1;
	if (solver.InitAll()) return -1;
	Handler hand(solver.config);
	if (hand) {
		hand.Init(&solver);
	}
	if (solver.RunMainLoop()) return -1;
	return 0;
}


